[
  {
    "objectID": "another-page.html",
    "href": "another-page.html",
    "title": "K-Means Analysis",
    "section": "",
    "text": "To conduct the \\(k\\)-means analysis, only numerical variables were included, and they were all standardized. Then, an elbow plot was constructed to see the optimal amount of clusters to conduct the \\(k\\)-means analysis."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Following the Line of Music",
    "section": "",
    "text": "In recent years, music has taken up a significant share of our media consumption - with the rise of digital media services and social media, consumers have little to no barriers to discovering, accessing, and engaging with music (Lee (2025)). This observation sparked curiosity in music analysis: we typically think of factors such as genre, lyricism, harmonic frequency, and artist connectivity as being integral to what makes music, music, but what is less clear is which factors really have an impact on the popularity and spread of music. Through this project, we aim to investigate music as a system of patterns, relationships, and compositions, as well as to uncover insights into how music is built, connected, and expressed.\nTo analyze these different components of music, we utilize three methods:\n1. \\(K\\)-means analysis to see if there is a “formula,” in regards to track features, in determining track popularity.\n2. Sentiment analysis to see any lyrics trends across songs, moods, and genres.\n3. Network map - to view relationships between artists and the industry"
  },
  {
    "objectID": "index.html#website-project-structure",
    "href": "index.html#website-project-structure",
    "title": "Following the Line of Music",
    "section": "Website project structure",
    "text": "Website project structure\nThe website project folder/repo will contain the following files, at a minimum:\n\n_quarto.yml: A configuration file that controls the YAML content, similar to what we typically see at the top of our qmd files.\nUse this file to add or remove additional subpages, change the overall website title, customize the navigation bar contents and layout, change the website theme, and set any other default formatting options such as code chunk options.\nindex.qmd: This is the landing page of your website. This file must be called index.qmd and must be located in the root directory of the project.\nUse this page, at a minimum, to introduce your project. From there you can either fully include the contents of the project or use additional qmd files to create subpages of your website (perhaps explaining the structure of the website to the user on this landing page).\nbib folder: Contains the bibliography file, which you should edit to include your resources, and a .csl file that tells Quarto how to format in-text citations and the bibliography list according to the American Statistical Association citation style.\ndocs folder: The rendered content of the website will be located here.\nstyles.css: This file is currently empty, but if you want to modify or replace the default theme, do so here using CSS. Students in the past have used custom color palettes or custom fonts, for example.\nAdditional qmd files: If you want to add subpages with their own content, create new qmd files in your root directory to do so, being sure to include them in the list of contents in your _quarto.yml file.\n\n\nOther recommended content:\nSimilar to the Shiny project, you will need to organize your wrangling scripts and data. You may also have other images or figures saved for displaying in your blog that will also need to be organized. Here are recommendations for organization.\n\nscripts: Store wrangling scripts in their own folder\ndata: Store datasets in their own folder, being sure to separate raw data from clean/processed data. You can do this in one of two ways: two separate data folders in the root directory (e.g., raw-data and data) or two subfolders of a single data folder (subfolders called, for example, raw, processed).\nimages: Organize saved images or figures together in their own folder. Make sure you keep track of the source of the images or figures and credit the sources in some way in your page (include source in caption and/or link image to source)"
  },
  {
    "objectID": "index.html#workflow",
    "href": "index.html#workflow",
    "title": "Following the Line of Music",
    "section": "Workflow",
    "text": "Workflow\n\nEdit contents of any files. Each new qmd file is a self-contained environment, so you will need to load any necessary packages and datasets for rendering that particular file at the top of that file.\nAfter updating a qmd file, Render the qmd file. Note that the rendered files (.html etc) are in the docs folder. Keep them there!\nCommit changes to website and PUSH to publish those changes."
  },
  {
    "objectID": "index.html#cross-referencing",
    "href": "index.html#cross-referencing",
    "title": "Following the Line of Music",
    "section": "Cross-referencing",
    "text": "Cross-referencing\nYou should use code chunk labels and in-text cross-references for figures and tables (see the Knitr examples at the link).\nQuarto additionally provides similar syntax for creating labels for and cross-referencing equations, creating labels for and cross-referencing sections, and using code chunk options of the form lst-label: lst-your-listing-label and lst-cap: Code chunk caption to be able to cross-reference displayed code chunks (or “listings”) using the syntax @lst-your-listing-label within the text.\nThese are not required for this project but are good practice."
  },
  {
    "objectID": "index.html#creating-and-linking-to-subpages",
    "href": "index.html#creating-and-linking-to-subpages",
    "title": "Following the Line of Music",
    "section": "Creating and linking to subpages",
    "text": "Creating and linking to subpages\nYou can create subpages by simply creating new qmd files. Any subpage you want to include on the website should be added to the website navigation list in the _quarto.yml file.\nYou can link to another page on the website by using just the filepath to the corresponding qmd file. You can also link directly to a section of a subpage."
  },
  {
    "objectID": "index.html#creating-the-bibliography",
    "href": "index.html#creating-the-bibliography",
    "title": "Following the Line of Music",
    "section": "Creating the bibliography",
    "text": "Creating the bibliography\nOne of the new challenges of Quarto, relative to a Word or Google doc, is learning how to build a bibliography and use the specified citation keys to write in-text citations.\nAll items you plan to cite should be added to the library.bib bibliography file, which you can open from within RStudio and edit just like any other text file. You should use standard bibtex syntax for each entry, following the examples provided. If the resource you are using doesn’t already provide a way to generate a bibtex entry, I recommend using zoterobib to generate the appropriate syntax (must change the Bibliography style to “BibTeX generic citation style”). The entries currently in library.bib are intended to provide syntax examples that capture the range of entries you are most likely to use. You will need to delete and replace the contents of library.bib with your own citation entries.\n\n\n\n\n\n\nNote\n\n\n\nThe examples in library.bib are nicely formatted so you can read and follow the patterns, but formatting and order of the library.bib file doesn’t actually matter and will not be assessed. Just be sure the citations are as complete as possible (authors, titles, dates, urls, dois, etc.).\n\n\n@book{hadley2016,\n  author = {Hadley, Wickham}, \n  title = {ggplot2: Elegant Graphics for Data Analysis}, \n  url  = {https://ggplot2-book.org},\n  publisher = {Springer},\n  address = {New York, NY},\n  type = {Online book},\n  year = {2016},\n  edition = {3}\n}"
  },
  {
    "objectID": "index.html#creating-in-text-citations",
    "href": "index.html#creating-in-text-citations",
    "title": "Following the Line of Music",
    "section": "Creating in-text citations",
    "text": "Creating in-text citations\nItems you cite in the text will be automatically added to a list of References at the bottom of the corresponding page. To cite a reference in the text, use the corresponding citation key (the first item in each bibtex entry—it shouldn’t have any spaces or special characters) and format the citation using the appropriate quarto format for in-text citations. This is similar to how we cross-reference tables and figures from code chunk labels. For example, the syntax\n@hadley2016 provides excellent examples of customizing our visualizations using **ggplot2**.\nproduces the following text:\n\n(hadley2016?) provides excellent examples of customizing our visualizations using ggplot2.\n\nAnd the corresponding reference is listed in full at the bottom of this page."
  },
  {
    "objectID": "index.html#including-images-or-gifs",
    "href": "index.html#including-images-or-gifs",
    "title": "Following the Line of Music",
    "section": "Including images or gifs",
    "text": "Including images or gifs\nI would strongly recommend using knitr’s include_graphics() functions within code chunks to include images or gifs within your blog. This makes it easier to modify figures, add captions and links, and visually find the code for figures quickly if you need to modify something about the output. There is also markdown syntax to display or embed images, but I would typically not recommend it.\n\n\n\n\n\n\n\n\n\nImage courtesy of giphy.com\n\n\n\n\nEither approach will take either a filepath to a stored file or a URL to an image or gif. Width can be specified as a percentage of the width of the page (0% to 100%; my preferred approach) or as a fixed number of units (e.g. 400px, 3in, 10cm).\nI can’t imagine a scenario where students should or would include videos within their blog, but Quarto provides guidance on embedding videos, as well.\n\n\n\n\n\n\nNote\n\n\n\nThe first figure of your blog will be used as the display image on our course’s landing page!"
  },
  {
    "objectID": "index.html#panel-tabsets",
    "href": "index.html#panel-tabsets",
    "title": "Following the Line of Music",
    "section": "Panel tabsets",
    "text": "Panel tabsets\nUse the following format to add information or tables or visualizations in tabset panels.\n\nTab 1Tab 2\n\n\nSome information in one tab\n\n\nSome information in a different tab"
  },
  {
    "objectID": "index.html#panel-layouts-for-content",
    "href": "index.html#panel-layouts-for-content",
    "title": "Following the Line of Music",
    "section": "Panel layouts for content",
    "text": "Panel layouts for content\nUse the following format to have more control over the panel layout of various components.\nThe syntax “[ [1], [1,1] ]” indicates that we have three pieces of content that we want to spread across two rows. The first piece of content will be in its own row, and then the next two components will be split across two columns of equal width in a second row.\n\n\n\n\n\n\nRow 1 with only one output\nSome content\n\n\n\n\nFirst column of row 2\nSome other content\n\n\nSecond column of row 2\nSome additional content.\n\n\n\nThe values provided within each row specify the relative widths of the content within that row. For example “[1,2,1]” would create a row with 3 columns where the first and third columns are the same width and the middle column is twice as wide."
  },
  {
    "objectID": "index.html#layouts-for-tables-and-visualizations-produced-by-code-chunks",
    "href": "index.html#layouts-for-tables-and-visualizations-produced-by-code-chunks",
    "title": "Following the Line of Music",
    "section": "Layouts for tables and visualizations produced by code chunks",
    "text": "Layouts for tables and visualizations produced by code chunks\nFor details on how to layout subfigures from multiple graphs produced by the same code chunk, see the examples in the Knitr tabs of the sections on figure layouts, subcaptions, and custom layouts.\nThe same syntax shown across the linked examples can be used to create subtables by replacing fig-cap and fig-subcap with tbl-cap and tbl-subcap.\nTwo examples in Table 1 and Figure 1 below are borrowed and slightly modified from the linked sections.\n\n\n\nTable 1: Two tables side-by-side\n\n\n\n\n\n\n\n(a) First three rows of cars dataset\n\n\n\n\n\nspeed\ndist\n\n\n\n\n4\n2\n\n\n4\n10\n\n\n7\n4\n\n\n\n\n\n\n\n\n\n\n\n(b) First three rows of pressure dataset\n\n\n\n\n\ntemperature\npressure\n\n\n\n\n0\n0.0002\n\n\n20\n0.0012\n\n\n40\n0.0060\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) cars\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(b) pressure\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) mtcars\n\n\n\n\n\n\n\nFigure 1: Three figures in a complex layout"
  },
  {
    "objectID": "yet-another-page.html",
    "href": "yet-another-page.html",
    "title": "Website title",
    "section": "",
    "text": "This is yet another page that can be linked! You are not required to include more than just index.qmd, but you are welcome to make content on different pages, if desired. This may help with managing GitHub commits, as well."
  },
  {
    "objectID": "yet-another-page.html#sec-note",
    "href": "yet-another-page.html#sec-note",
    "title": "Website title",
    "section": "A note",
    "text": "A note\nNotice that you can also modify the YAML headings at the top of each page as I did in the first subpage or completely delete them, as I did here."
  },
  {
    "objectID": "index.html#k-means-analysis",
    "href": "index.html#k-means-analysis",
    "title": "Following the Line of Music",
    "section": "K-Means Analysis",
    "text": "K-Means Analysis\nTo conduct the \\(k\\)-means analysis, only numerical variables were included, and they were all standardized. Then, an elbow plot was constructed to see the optimal amount of clusters to conduct the \\(k\\)-means analysis.\n\nElbow Plot\n\n\n\n\n\n\n\n\n\n\n\nK-Means Analysis Visualizations"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Following the Line of Music",
    "section": "",
    "text": "In recent years, music has taken up a significant share of our media consumption - with the rise of digital media services and social media, consumers have little to no barriers to discovering, accessing, and engaging with music (Lee (2025)). This observation sparked curiosity in music analysis: we typically think of factors such as genre, lyricism, harmonic frequency, and artist connectivity as being integral to what makes music, music, but what is less clear is which factors really have an impact on the popularity and spread of music. Through this project, we aim to investigate music as a system of patterns, relationships, and compositions, as well as to uncover insights into how music is built, connected, and expressed.\nTo analyze these different components of music, we utilize three methods:\n1. \\(K\\)-means analysis to see if there is a “formula,” in regards to track features, in determining track popularity.\n2. Sentiment analysis to see any lyrics trends across songs, moods, and genres.\n3. Network map - to view relationships between artists and the industry"
  },
  {
    "objectID": "another-page.html#k-means-analysis",
    "href": "another-page.html#k-means-analysis",
    "title": "K-Means Analysis",
    "section": "",
    "text": "To conduct the \\(k\\)-means analysis, only numerical variables were included, and they were all standardized. Then, an elbow plot was constructed to see the optimal amount of clusters to conduct the \\(k\\)-means analysis."
  },
  {
    "objectID": "network-map.html#subtitle",
    "href": "network-map.html#subtitle",
    "title": "Network Map",
    "section": "Subtitle",
    "text": "Subtitle"
  },
  {
    "objectID": "sentiment-analysis.html#subtitle",
    "href": "sentiment-analysis.html#subtitle",
    "title": "Sentiment Analysis",
    "section": "Subtitle",
    "text": "Subtitle"
  },
  {
    "objectID": "k-means.html",
    "href": "k-means.html",
    "title": "K-Means Analysis",
    "section": "",
    "text": "To observe patterns and relationships amongst the top songs on Spotify, unsupervised learning was utilized through \\(k\\)-means analysis. \\(K\\)-means analysis includes assigning each track to a distinct group based on similarities in track features; thus, the purpose of clustering is to see if there are any distinguishable “groupings” between different tracks. Through cluster analysis, we hope to see if there are specific track features that have a larger impact on a track’s popularity. For instance, we often think that more “hype” songs have a higher likelihood of being popular than slower, more melancholy songs; in this case, we would expect that clusters with a higher popularity would also score higher on danceability and energy.\nBecause \\(k\\)-means analysis can only be conducted on numerical data, all qualitative variables were removed. Then, the data was standardized to ensure that no one variable had a significant impact on the clustering. For example, track_popularity was recorded on a much larger scale (0-100) than the other variables, which were on a scale from 0-1. Then, an elbow plot was constructed to see the optimal amount of clusters to conduct the \\(k\\)-means analysis. Finally, visualizations were generated to see differences amongst clusters.\nTo conduct the data wrangling and analysis for the \\(k\\)-means clustering, the following packages were used:\n- tidyverse by Wickham et al. (2019)\n- purrr by Wickham and Henry (2023)\n- broom by Robinson et al. (2024)\n- ggplot2 by Wickham (2016) - to create the elbow plot to determine the optimal amount of clusters\n- GGally by Schloerke et al. (2024) - to generate visualizations for the \\(k\\)-means analysis\n- citation by Dietrich and Leoncio (2023) - to generate citations"
  },
  {
    "objectID": "k-means.html#k-means-analysis",
    "href": "k-means.html#k-means-analysis",
    "title": "K-Means Analysis",
    "section": "",
    "text": "To conduct the \\(k\\)-means analysis, only numerical variables were included. Then, the data was standardized to ensure that no one variable had a significant impact on the clustering (for example, track_popularity was on a much larger scale - 0-100 - than other variables - 0-1). Then, an elbow plot was constructed using the ggplot2 package by Wickham (2016) to see the optimal amount of clusters to conduct the \\(k\\)-means analysis. Finally, visualizations for the \\(k\\)-means analysis were generated using the tidyverse package by Wickham et al. (2019) and GGally package by Schloerke et al. (2024).\n\n\nFrom the tidytuesday Spotify dataset by Thompson et al. (2020), 13 variables were used.\n- track_popularity: ranging from 0 (least popular) to 100 (most popular)\n- danceability: ranging from 0.0 (least danceable) to 1.0 (most danceable), determined based on tempo, rhythm stability, beat strength, and overall regularity\n- energy: ranging from 0.0 (less energetic) to 1.0 (more energetic), determined by dynamic range, perceived loudness, timbre, onset rate, and general entropy\n- key: the estimated overall key of the track, where 0 = C, 1 = C#, 2 = D, and so on\n- loudness: the average loudness in decibels\n- mode: the modality of a track, either 1 (major) or 0 (minor)\n- speechiness: the presence of spoken words in a track, ranging from 0 (non-speech-like tracks) to 1.0 (exclusively speech-like)\n- acousticness: ranging from 0.0 (low confidence the track is acoustic) to 1.0 (high confidence)\n- instrumentalness: predicts whether a track contains no vocals, ranging from 0.0 (lower likelihood of no vocal content) to 1.0 (higher likelihood); “ooh” and “aah” are treated as instrumental\n- liveness: detects the presence of an audience, ranging from 0.0 (low probability the track was performed live) to 1.0 (high probability the track was performed live)\n- valence: describes the musical positiveness conveyed by the track, ranging from 0.0 (more negative) to 1.0 (more positive)\n- tempo: the average tempo in beats per minute\n- duration_ms: duration of the song in milliseconds\n\n\n\n\n\n\n\n\n\n\n\n\nThe elbow plot indicates that there are no significant drops in the total within-cluster sum of squares after 4 clusters, so 4 clusters was used for our \\(k\\)-means analysis.\n\n\n\nFour plots were generated to visualize the differences between clusters, with each plot comparing three different variables with popularity scores. Click through the tabset panels to explore the different visualizations. The title of each panel indicates the three variables that were used to compare clusters and popularity scores.\n\nDanceability, Energy, LivenessKey, Tempo, DurationSpeechiness, Acousticness, InstrumentalnessValence, Mode, Loudness\n\n\n\n\n\n\n\n\n\n\n\nAll four clusters had relatively high danceability scores, with cluster 3 having the highest and cluster 2 having the lowest. Cluster 4 had the lowest energy score, while cluster 3 had the second lowest. Clusters 1 and 2 had similarly high energy scores. All four clusters had low liveness scores.\n\n\n\n\n\n\n\n\n\n\n\nThere were no significant differences in the key, tempo, and duration of the four clusters.\n\n\n\n\n\n\n\n\n\n\n\nAll four clusters had extremely low speechiness scores. Clusters 1 and 2 had low acousticness scores, with cluster 3 having a slightly higher score, and cluster 4 having a substantialy higher acousticness score. Clusters 2, 3, and 4 had extremely low instrumentalness scores, while cluster 1 had an extremely high instrumentalness score.\n\n\n\n\n\n\n\n\n\n\n\nClusters 1, 2, and 4 had similar valence scores, while cluster 3 had a higher valence score. There was no difference in the mode of the four clusters. Clusters 1, 2, and 3 had similar loudness scores, and cluster 4 had a slightly lower loudness score.\n\n\n\nOverall, there was no significant difference in the popularity scores of the four clusters. The order of the popularity scores (from highest to lowest) is cluster 3, cluster 4, cluster 2, cluster 1. The most notable differences between clusters included:\n- Cluster 4 had a much lower energy score\n- Cluster 1 scored much higher on instrumentalness\n- Cluster 3 scored relatively higher on valence\n\n\n\nPackages used to wrangle this data prior to data analysis were tidyverse by Wickham et al. (2019), purrr by Wickham and Henry (2023), and broom by Robinson et al. (2024)."
  },
  {
    "objectID": "index.html#dataset",
    "href": "index.html#dataset",
    "title": "Following the Line of Music",
    "section": "Dataset",
    "text": "Dataset\nData on various songs was taken from the TidyTuesday Spotify dataset by Thompson et al. (2020). Included in the dataset was information about the track (such as the name, artist, and genre), and audio features (such as the danceability, tempo, and duration). Release dates of the songs in the dataset range from 1957 to 2020.\nThen, song lyrics were scraped from Genius (2025).\nFinally, general information on each track was scraped from Wikipedia (2025)."
  },
  {
    "objectID": "index.html#limitations",
    "href": "index.html#limitations",
    "title": "Following the Line of Music",
    "section": "Limitations",
    "text": "Limitations\nBecause songs were taken between 1957 to 2020, these results only apply to tracks from that time period. Due to the COVID-19 pandemic, online streaming platforms faced increased demand, leading to a higher quantity of music being produced every year Sarmiento et al. (2025). Thus, this sudden change in supply and demand may make the results of this study ungeneralizable beyond 2020.\nOriginally, we attempted to scrape data on current popular songs using the spotifyr package; however, because Spotify no longer allows for users to get data on tracks, we were unable to do so. Thus, with easier access to current data, we would be more able to analyze current trends and relationships in the music industry.\nIn the future, this project can be improved by using more recent data, as well as having access to scrape track data. Additionally, it would be interesting to see any trends between different streaming platforms, such as Apple Music and YouTube music. Because other countries use different streaming platforms (for example, people in China mainly use QQ music, as Spotify is blocked), trends across different countries and cultures could also be investigated."
  },
  {
    "objectID": "index.html#conclusion",
    "href": "index.html#conclusion",
    "title": "Following the Line of Music",
    "section": "Conclusion",
    "text": "Conclusion\nCitations were generated using the citation by Dietrich and Leoncio (2023) package."
  },
  {
    "objectID": "k-means.html#introduction",
    "href": "k-means.html#introduction",
    "title": "K-Means Analysis",
    "section": "",
    "text": "To observe patterns and relationships amongst the top songs on Spotify, unsupervised learning was utilized through \\(k\\)-means analysis. \\(K\\)-means analysis includes assigning each track to a distinct group based on similarities in track features; thus, the purpose of clustering is to see if there are any distinguishable “groupings” between different tracks. Through cluster analysis, we hope to see if there are specific track features that have a larger impact on a track’s popularity. For instance, we often think that more “hype” songs have a higher likelihood of being popular than slower, more melancholy songs; in this case, we would expect that clusters with a higher popularity would also score higher on danceability and energy.\nBecause \\(k\\)-means analysis can only be conducted on numerical data, all qualitative variables were removed. Then, the data was standardized to ensure that no one variable had a significant impact on the clustering. For example, track_popularity was recorded on a much larger scale (0-100) than the other variables, which were on a scale from 0-1. Then, an elbow plot was constructed to see the optimal amount of clusters to conduct the \\(k\\)-means analysis. Finally, visualizations were generated to see differences amongst clusters.\nTo conduct the data wrangling and analysis for the \\(k\\)-means clustering, the following packages were used:\n- tidyverse by Wickham et al. (2019)\n- purrr by Wickham and Henry (2023)\n- broom by Robinson et al. (2024)\n- ggplot2 by Wickham (2016) - to create the elbow plot to determine the optimal amount of clusters\n- GGally by Schloerke et al. (2024) - to generate visualizations for the \\(k\\)-means analysis\n- citation by Dietrich and Leoncio (2023) - to generate citations"
  },
  {
    "objectID": "k-means.html#variables",
    "href": "k-means.html#variables",
    "title": "K-Means Analysis",
    "section": "Variables",
    "text": "Variables\nFrom the tidytuesday Spotify dataset by Thompson et al. (2020), 13 variables were used.\n- track_popularity: ranging from 0 (least popular) to 100 (most popular)\n- danceability: ranging from 0.0 (least danceable) to 1.0 (most danceable), determined based on tempo, rhythm stability, beat strength, and overall regularity\n- energy: ranging from 0.0 (less energetic) to 1.0 (more energetic), determined by dynamic range, perceived loudness, timbre, onset rate, and general entropy\n- key: the estimated overall key of the track, where 0 = C, 1 = C#, 2 = D, and so on\n- loudness: the average loudness in decibels\n- mode: the modality of a track, either 1 (major) or 0 (minor)\n- speechiness: the presence of spoken words in a track, ranging from 0 (non-speech-like tracks) to 1.0 (exclusively speech-like)\n- acousticness: ranging from 0.0 (low confidence the track is acoustic) to 1.0 (high confidence)\n- instrumentalness: predicts whether a track contains no vocals, ranging from 0.0 (lower likelihood of no vocal content) to 1.0 (higher likelihood); “ooh” and “aah” are treated as instrumental\n- liveness: detects the presence of an audience, ranging from 0.0 (low probability the track was performed live) to 1.0 (high probability the track was performed live)\n- valence: describes the musical positiveness conveyed by the track, ranging from 0.0 (more negative) to 1.0 (more positive)\n- tempo: the average tempo in beats per minute\n- duration_ms: duration of the song in milliseconds"
  },
  {
    "objectID": "k-means.html#elbow-plot",
    "href": "k-means.html#elbow-plot",
    "title": "K-Means Analysis",
    "section": "Elbow Plot",
    "text": "Elbow Plot\n\n\n\n\n\n\n\n\n\nThe elbow plot indicates that there are no significant drops in the total within-cluster sum of squares after 4 clusters (the highlighted point), so 4 clusters was used for our \\(k\\)-means analysis."
  },
  {
    "objectID": "k-means.html#visualizations",
    "href": "k-means.html#visualizations",
    "title": "K-Means Analysis",
    "section": "Visualizations",
    "text": "Visualizations\nFor clearer visualization, four separate plots were generated to visualize the differences between clusters, with each plot comparing three different variables with popularity scores. Click through the tabset panels to explore the different visualizations. The title of each panel indicates the three variables that were used to compare clusters and popularity scores. Each cluster is separated by color.\n\nDanceability, Energy, LivenessKey, Tempo, DurationSpeechiness, Acousticness, InstrumentalnessValence, Mode, Loudness\n\n\n\n\n\n\n\n\n\n\n\nAll four clusters had relatively high danceability scores, with cluster 3 having the highest and cluster 2 having the lowest. Cluster 4 had the lowest energy score, while cluster 3 had the second lowest. Clusters 1 and 2 had similarly high energy scores. All four clusters had low liveness scores.\n\n\n\n\n\n\n\n\n\n\n\nThere were no significant differences in the key, tempo, and duration of the four clusters.\n\n\n\n\n\n\n\n\n\n\n\nAll four clusters had extremely low speechiness scores. Clusters 1 and 2 had low acousticness scores, with cluster 3 having a slightly higher score, and cluster 4 having a substantialy higher acousticness score. Clusters 2, 3, and 4 had extremely low instrumentalness scores, while cluster 1 had an extremely high instrumentalness score.\n\n\n\n\n\n\n\n\n\n\n\nClusters 1, 2, and 4 had similar valence scores, while cluster 3 had a higher valence score. There was no difference in the mode of the four clusters. Clusters 1, 2, and 3 had similar loudness scores, and cluster 4 had a slightly lower loudness score.\n\n\n\nOverall, there was no significant difference in the popularity scores of the four clusters. The order of the popularity scores (from highest to lowest) is cluster 3, cluster 4, cluster 2, cluster 1. The most notable differences between clusters included:\n- Cluster 4 had a much lower energy score\n- Cluster 1 scored much higher on instrumentalness\n- Cluster 3 scored relatively higher on valence"
  },
  {
    "objectID": "k-means.html#conclusion",
    "href": "k-means.html#conclusion",
    "title": "K-Means Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nWhile no significant conclusions can be drawn, the \\(k\\)-means analysis suggests that more popular songs tend to score higher on valence. This means that consumers tend to like tracks that are more positive, compared to those that carry a negative tone. Additionally, less popular songs scored much higher on instrumentalness, which suggests that consumers tend to gravitate towards tracks with more lyrics and vocals."
  },
  {
    "objectID": "sentiment-analysis.html#what-words-are-the-most-popular-songs-using",
    "href": "sentiment-analysis.html#what-words-are-the-most-popular-songs-using",
    "title": "Sentiment Analysis",
    "section": "What words are the most popular songs using?",
    "text": "What words are the most popular songs using?\nAll data is from the top 100 spotify songs"
  },
  {
    "objectID": "network-map.html",
    "href": "network-map.html",
    "title": "Network Map w/ Additional Visuals",
    "section": "",
    "text": "To explore connections between artists among top Spotify tracks, we used network science to construct and analyze a collaboration network. In this network, each node represents a unique artist, and edges connect artists who have worked together before. By modeling these relationships as a network, we can observe how artists cluster together, which artists are central to the network, and how collaboration patterns vary across the music industry.\nNetwork analysis helps us do more than just count how many times artists worked together, it allows us to actually see how those collaborations are structured. By looking at the network, we can figure out which artists play important roles, like being central connectors between groups or part of particular circles that collaborate a lot. For example, we might expect pop artists to be part of big, connected clusters because they tend to collaborate more often, while artists from smaller or more niche genres might be more on the edges of the network. Given the use of this spotify dataset, when filter for top our tracks, a majority of the songs are pop genre, thus we will see many connections in the dominating pop genre circles.\nTo create the network, we first scrapped and downloaded information from Wikipedia to gain an understanding of which artist have crossed paths professionally. Then that data was filtered to include only unique artist-to-artist collaborations. Then, we used visualizations using centrality metrics to highlight popular artists amongst those groups to examine the overall connectivity of the network. Through this analysis, we hope to gain insight into how collaborative behavior influences visibility, crossovers with genre, and the formation of musical communities or pods.\n\n\nNumber of Variables used: Sources: 1. Tidytuesday Spotify dataset by Thompson et al. (2020) 2. Wikipedia Sites\nFor Map - track_artist: list of all artist who’s songs have made it to the top 100 songs - hometown: hometown is distinct from bornplace, hometown is where the artist grew up - Weight: how many artist were raised in a given location - geometry: spatial data that stored in polygons (boundary areas across the globe)\nBar –\nFor Network - track_artist: list of all artist who’s songs have made it to the top 100 songs - hometown: hometown is distinct from bornplace, hometown is where the artist grew up - collabArtist: the names of artist (exclusively artist listed in the top 100) who have worked with (in any capacity) with track artist"
  },
  {
    "objectID": "network-map.html#introduction",
    "href": "network-map.html#introduction",
    "title": "Network Map w/ Additional Visuals",
    "section": "",
    "text": "To explore connections between artists among top Spotify tracks, we used network science to construct and analyze a collaboration network. In this network, each node represents a unique artist, and edges connect artists who have worked together before. By modeling these relationships as a network, we can observe how artists cluster together, which artists are central to the network, and how collaboration patterns vary across the music industry.\nNetwork analysis helps us do more than just count how many times artists worked together, it allows us to actually see how those collaborations are structured. By looking at the network, we can figure out which artists play important roles, like being central connectors between groups or part of particular circles that collaborate a lot. For example, we might expect pop artists to be part of big, connected clusters because they tend to collaborate more often, while artists from smaller or more niche genres might be more on the edges of the network. Given the use of this spotify dataset, when filter for top our tracks, a majority of the songs are pop genre, thus we will see many connections in the dominating pop genre circles.\nTo create the network, we first scrapped and downloaded information from Wikipedia to gain an understanding of which artist have crossed paths professionally. Then that data was filtered to include only unique artist-to-artist collaborations. Then, we used visualizations using centrality metrics to highlight popular artists amongst those groups to examine the overall connectivity of the network. Through this analysis, we hope to gain insight into how collaborative behavior influences visibility, crossovers with genre, and the formation of musical communities or pods.\n\n\nNumber of Variables used: Sources: 1. Tidytuesday Spotify dataset by Thompson et al. (2020) 2. Wikipedia Sites\nFor Map - track_artist: list of all artist who’s songs have made it to the top 100 songs - hometown: hometown is distinct from bornplace, hometown is where the artist grew up - Weight: how many artist were raised in a given location - geometry: spatial data that stored in polygons (boundary areas across the globe)\nBar –\nFor Network - track_artist: list of all artist who’s songs have made it to the top 100 songs - hometown: hometown is distinct from bornplace, hometown is where the artist grew up - collabArtist: the names of artist (exclusively artist listed in the top 100) who have worked with (in any capacity) with track artist"
  },
  {
    "objectID": "sentiment-analysis.html#total-word-count",
    "href": "sentiment-analysis.html#total-word-count",
    "title": "Sentiment Analysis",
    "section": "Total Word Count",
    "text": "Total Word Count\n\nWord CloudList\n\n\nThis visual shows a word cloud including the top words from all songs.\n\n\n\n\n\n\n\n\n\n\n\nThis visual shows the top words used among all songs in general.\n\n\n\n\n\n\n\n\n\n\n\n\nThis visual shows the top words in terms of usage under each category of sentiment defined by nrc."
  },
  {
    "objectID": "sentiment-analysis.html#all-song-sentiments",
    "href": "sentiment-analysis.html#all-song-sentiments",
    "title": "Sentiment Analysis",
    "section": "All Song Sentiments",
    "text": "All Song Sentiments\n\nTop 10 SongsBottom 10 Songs\n\n\nThis visual shows the top ten songs in terms of sentiment according to afinn.\n\n\n\n\n\n\n\n\n\n\n\nThis visual shows the bottom ten songs in terms of sentiment according to afinn."
  },
  {
    "objectID": "sentiment-analysis.html#pop-vs.-rap",
    "href": "sentiment-analysis.html#pop-vs.-rap",
    "title": "Sentiment Analysis",
    "section": "Pop vs. Rap",
    "text": "Pop vs. Rap\n\nTop 10 SongsBottom 10 Songs\n\n\nThe next visual shows the top songs in terms of sentiment according to afinn categorized by genre.\n\n\n\n\n\n\n\n\n\n\n\nThe next visual shows the bottom songs in terms of sentiment according to afinn categorized by genre."
  }
]